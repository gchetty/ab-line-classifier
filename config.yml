PATHS:
  CLIPS_TABLE: 'data/clips_by_patients_cropped.csv'
  FRAME_TABLE: 'data/frames_actually_cropped.csv' #'data/frames.csv'   # Path to all LUS frames in the dataset
  QUERY_TABLE: 'data/clips.csv'
  DATABASE_QUERY: 'data/clips_query.sql'
  RAW_CLIPS: 'data/raw_clips/'
  MASKED_CLIPS: 'data/masked_clips/'
  FRAMES: 'data/data_actually_cropped/'
  PARTITIONS: 'data/partitions/'
  TEST_DF: 'data/partitions/test_set_final.csv'
  EXT_VAL_CLIPS_TABLE: 'data/clips_by_patient_mini.csv'
  EXT_VAL_FRAME_TABLE: 'data/frames_mini.csv'
  EXT_VAL_FRAMES: 'data/frames_mini/'
  HEATMAPS: 'img/heatmaps'
  LOGS: 'results/logs/'
  IMAGES: 'results/figures/'
  MODEL_WEIGHTS: 'results/models/'
  MODEL_TO_LOAD: 'results/models/cutoffvgg16_final_cropped.h5'
  CLASS_NAME_MAP: 'data/serializations/output_class_indices.pkl'
  BATCH_PREDS: 'results/predictions/'
  METRICS: './results/metrics/'
  EXPERIMENTS: './results/experiments/'
  EXPERIMENT_VISUALIZATIONS: './img/experiments/'
  PRETRAINED_WEIGHTS: 'B:\\Documents\\Work\\DeepBreathe\\projects\\ssl_ab\\backbones\\simclr\\20220918-120648_mobilenetv2'
  RT_ROOT_DIR: 'data/WB-Prospective-Data-Trimmed/'
  RT_LABELBOX_ANNOTATIONS: 'data/processed_labelbox_phase1.csv'
  AUTOMASK_MODEL_PATH: 'data/auto_masking_deeper.h5'
  HOLDOUT_CLIPS_PATH: 'data/holdout_clips.csv'
  HOLDOUT_FRAMES_PATH: 'data/holdout_frames.csv'
  MODEL_DEV_CLIPS_PATH: 'data/model_dev_clips.csv'
  MODEL_DEV_FRAMES_PATH: 'data/model_dev_frames.csv'
  K_FOLDS_SPLIT_PATH: 'data/'


WANDB:
  ENTITY: 'deep-breathe'
  PROJECT_NAME: 'ab_line'
  LOGGING:
    IMAGES: False
    MODEL_DEV_HOLDOUT: False
    K_FOLD_CROSS_VAL: False
    TRAIN_TEST_VAL: False
  IMAGES_ARTIFACT_VERSION: ''
  MODEL_DEV_ARTIFACT_VERSION: ''
  TRAIN_VAL_TEST_ARTIFACT_VERSION: ''
  ARTIFACT_SEED: 42

DATA:
  IMG_DIM: [128, 128]
  VAL_SPLIT: 0.1
  TEST_SPLIT: 0.1
  HOLDOUT_ARTIFACT_SPLIT: 0.1
  CLASSES: ['a_lines', 'b_lines']   # Classes for binary classification
  RT_B_LINES_3_CLASS: 'b_lines'
  REAL_TIME_DATA: False
  AUTOMASK:
    VERSION: 'wavebase'
    OUTPUT_FORMAT: 'mp4'
    EDGE_PRESERVE: 0.95
    SAVE_CROPPED_ROI: True

TRAIN:
  MODEL_DEF: 'cutoffvgg16'   # One of {'vgg16', 'mobilenetv2', 'xception', 'efficientnetb7', 'custom_resnetv2', 'cutoffvgg16'}
  EXPERIMENT_TYPE: 'single_train'               # One of {'single_train', 'cross_validation', 'hparam_search'}
  SEED: 10001
  N_CLASSES: 2
  BATCH_SIZE: 64
  EPOCHS: 30
  PATIENCE: 15
  MIXED_PRECISION: false                         # Necessary for training with Tensor Cores
  N_FOLDS: 5
  USE_MEMORY_LIMIT: False
  MEMORY_LIMIT: 21672
  USE_PRETRAINED: False
  DATA_AUG:
    ZOOM_RANGE: 0.1
    HORIZONTAL_FLIP: true
    WIDTH_SHIFT_RANGE: 0.2
    HEIGHT_SHIFT_RANGE: 0.2
    SHEAR_RANGE: 10
    ROTATION_RANGE: 45
    BRIGHTNESS_RANGE: 0.3
  HPARAM_SEARCH:
    N_EVALS: 10
    HPARAM_OBJECTIVE: 'auc'

CLIP_PREDICTION:
  ALGORITHM: 'average'       # One of "contiguous", "sliding_window" or "average"
  CLASSIFICATION_THRESHOLD: 0.7
  CONTIGUITY_THRESHOLD: 3
  SLIDING_WINDOW: 4

HPARAMS:
  MOBILENETV2:
    LR: 0.0001
    DROPOUT: 0.35
    L2_LAMBDA: 0.001
    NODES_DENSE0: 32
    FREEZE_IDX: 116
    CUTOFF_IDX: 115
  SHUFFLENETV2:
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
  VGG16:
    LR: 0.01
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
    NODES_DENSE0: 64
    FREEZE_IDX: -1
  XCEPTION:
    LR: 0.01
    DROPOUT: 0.5
    FREEZE_IDX: -1
    L2_LAMBDA: 0.01
  BiTR50x1:
    #https://blog.tensorflow.org/2020/05/bigtransfer-bit-state-of-art-transfer-learning-computer-vision.html
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
  EFFICIENTNETB7:
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
    FREEZE_IDX: -1
  CNN0:
    LR: 0.001
    DROPOUT: 0.35
    L2_LAMBDA: 0.0001
    NODES_DENSE0: 64
    KERNEL_SIZE: 3
    STRIDES: 1
    MAXPOOL_SIZE: 2
    BLOCKS: 4
    INIT_FILTERS: 32
    FILTER_EXP_BASE: 2
  CUSTOM_RESNETV2:
    LR: 0.000046
    DROPOUT0: 0.45
    DROPOUT1: 0.40
    STRIDES: 1
    BLOCKS: 2
    INIT_FILTERS: 16
  CUTOFFVGG16:
    LR_EXTRACT: 0.0003
    LR_FINETUNE: 0.0000093
    DROPOUT: 0.45
    CUTOFF_LAYER: 10
    FINETUNE_LAYER: 7
    EXTRACT_EPOCHS: 6

HPARAM_SEARCH:
  MOBILENETV2:
    LR:
      TYPE: 'float_log'
      RANGE: [0.00001, 0.001]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [0.0, 0.5]
  CUTOFFVGG16:
    LR_EXTRACT:
      TYPE: 'float_log'
      RANGE: [0.00001, 0.001]
    LR_FINETUNE:
      TYPE: 'float_log'
      RANGE: [0.000001, 0.00001]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [0.0, 0.5]
    EXTRACT_EPOCHS:
      TYPE: 'int_uniform'
      RANGE: [2,10]
  CUSTOM_RESNETV2:
    LR:
      TYPE: 'float_log'
      RANGE: [ 0.00001, 0.001 ]
    DROPOUT0:
      TYPE: 'float_uniform'
      RANGE: [ 0.0, 0.5 ]
    DROPOUT1:
      TYPE: 'float_uniform'
      RANGE: [ 0.2, 0.5 ]
    BLOCKS:
      TYPE: 'int_uniform'
      RANGE: [1, 3]
    INIT_FILTERS:
      TYPE: 'set'
      RANGE: [16, 32]

EXPLAINABILITY:
  GRAD_CAM:
    MODE: 'normal'  # One of {'normal', 'plusplus'} to determine weight formulas when computing heatmaps