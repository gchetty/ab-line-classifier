PATHS:
  CLIPS_TABLE: 'data/clips_by_patient_cropped.csv'
  FRAME_TABLE: 'data/frames.csv'   # Path to all LUS frames in the dataset
  DATABASE_QUERY: 'data/parenchymal_clips.csv'
  RAW_CLIPS: 'data/raw_clips/'
  FRAMES: 'B:/Datasets/Ottawa/pure_and_muggle/frames/'
  PARTITIONS: 'data/partitions/'
  TEST_DF: 'data/partitions/test_set_final.csv'
  EXT_VAL_CLIPS_TABLE: 'data/clips_by_patient_mini.csv'
  EXT_VAL_FRAME_TABLE: 'data/frames_mini.csv'
  EXT_VAL_FRAMES: 'data/frames_mini/'
  HEATMAPS: 'img/heatmaps'
  LOGS: 'results/logs/'
  IMAGES: 'results/figures/'
  MODEL_WEIGHTS: 'results/models/'
  MODEL_TO_LOAD: 'results/models/cutoffvgg16_final_cropped.h5'
  CLASS_NAME_MAP: 'data/serializations/output_class_indices.pkl'
  BATCH_PREDS: 'results/predictions/'
  METRICS: './results/metrics/'
  EXPERIMENTS: './results/experiments/'
  EXPERIMENT_VISUALIZATIONS: './img/experiments/'

DATA:
  IMG_DIM: [128, 128]
  VAL_SPLIT: 0.1
  TEST_SPLIT: 0.1
  CLASSES: ['a_lines', 'b_lines']   # Classes for binary classification

TRAIN:
  MODEL_DEF: 'cutoffvgg16'   # One of {'vgg16', 'mobilenetv2', 'xception', 'efficientnetb7', 'custom_resnetv2', 'cutoffvgg16'}
  EXPERIMENT_TYPE: 'single_train'               # One of {'single_train', 'cross_validation', 'hparam_search'}
  N_CLASSES: 2
  BATCH_SIZE: 256
  EPOCHS: 15
  PATIENCE: 15
  METRIC_PREFERENCE: ['auc', 'recall', 'precision', 'loss']
  NUM_GPUS: 1
  MIXED_PRECISION: false                         # Necessary for training with Tensor Cores
  N_FOLDS: 10
  DATA_AUG:
    ZOOM_RANGE: 0.1
    HORIZONTAL_FLIP: true
    WIDTH_SHIFT_RANGE: 0.2
    HEIGHT_SHIFT_RANGE: 0.2
    SHEAR_RANGE: 10
    ROTATION_RANGE: 45
    BRIGHTNESS_RANGE: [0.7, 1.3]
  HPARAM_SEARCH:
    N_EVALS: 10
    HPARAM_OBJECTIVE: 'auc'

CLIP_PREDICTION:
  ALGORITHM: 'average'       # One of "contiguous", "sliding_window" or "average"
  CLASSIFICATION_THRESHOLD: 0.5
  CONTIGUITY_THRESHOLD: 4
  SLIDING_WINDOW: 4

HPARAMS:
  MOBILENETV2:
    LR: 0.001
    DROPOUT: 0.35
    L2_LAMBDA: 0.0001
    NODES_DENSE0: 32
    FROZEN_LAYERS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,16,17,18,19,20,21,22,23,24,25,26,26,27,28,29,30]
  SHUFFLENETV2:
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
  VGG16:
    LR: 0.01
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
    NODES_DENSE0: 64
    FROZEN_LAYERS: []
  XCEPTION:
    LR: 0.01
    DROPOUT: 0.5
    FROZEN_LAYERS: []
    L2_LAMBDA: 0.01
  BiTR50x1:
    #https://blog.tensorflow.org/2020/05/bigtransfer-bit-state-of-art-transfer-learning-computer-vision.html
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
  EFFICIENTNETB7:
    LR: 0.1
    DROPOUT: 0.5
    L2_LAMBDA: 0.01
    FROZEN_LAYERS: []
  CNN0:
    LR: 0.001
    DROPOUT: 0.35
    L2_LAMBDA: 0.0001
    NODES_DENSE0: 64
    KERNEL_SIZE: 3
    STRIDES: 1
    MAXPOOL_SIZE: 2
    BLOCKS: 4
    INIT_FILTERS: 32
    FILTER_EXP_BASE: 2
  CUSTOM_RESNETV2:
    LR: 0.000046
    DROPOUT0: 0.45
    DROPOUT1: 0.40
    STRIDES: 1
    BLOCKS: 2
    INIT_FILTERS: 16
  CUTOFFVGG16:
    LR_EXTRACT: 0.0003
    LR_FINETUNE: 0.0000093
    DROPOUT: 0.45
    CUTOFF_LAYER: 10
    FINETUNE_LAYER: 7
    EXTRACT_EPOCHS: 6

HPARAM_SEARCH:
  MOBILENETV2:
    LR:
      TYPE: 'float_log'
      RANGE: [0.00001, 0.001]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [0.0, 0.5]
  CUTOFFVGG16:
    LR_EXTRACT:
      TYPE: 'float_log'
      RANGE: [0.00001, 0.001]
    LR_FINETUNE:
      TYPE: 'float_log'
      RANGE: [0.000001, 0.00001]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [0.0, 0.5]
    EXTRACT_EPOCHS:
      TYPE: 'int_uniform'
      RANGE: [2,10]
  CUSTOM_RESNETV2:
    LR:
      TYPE: 'float_log'
      RANGE: [ 0.00001, 0.001 ]
    DROPOUT0:
      TYPE: 'float_uniform'
      RANGE: [ 0.0, 0.5 ]
    DROPOUT1:
      TYPE: 'float_uniform'
      RANGE: [ 0.2, 0.5 ]
    BLOCKS:
      TYPE: 'int_uniform'
      RANGE: [1, 3]
    INIT_FILTERS:
      TYPE: 'set'
      RANGE: [16, 32]